#!/usr/bin/env python3
"""
Smart Detection Pipeline Demo

Demonstrates the prioritized detection system that uses:
1. OpenCV (fast) - motion detection, HOG person detection
2. Small LLM (medium) - quick checks, summaries
3. Large LLM (slow) - full descriptions when needed

Usage:
    python smart_detection_demo.py --intent "track person"
    python smart_detection_demo.py --intent "notify when someone enters"
    python smart_detection_demo.py --intent "security monitoring"
"""

import argparse
import sys
from pathlib import Path

# Add parent to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from streamware.detection_pipeline import (
    DetectionPipeline, 
    UserIntent, 
    parse_user_intent,
    LLM_REGISTRY,
    get_best_llm_for_task,
)


def demo_intent_parsing():
    """Demonstrate intent parsing from natural language."""
    print("\n" + "="*60)
    print("INTENT PARSING DEMO")
    print("="*60)
    
    examples = [
        "track person in the room",
        "notify me when someone enters",
        "alert when person leaves",
        "security monitoring",
        "log all activity",
        "watch what they're doing",
        "Å›ledÅº osobÄ™",  # Polish
        "powiadom gdy ktoÅ› wejdzie",  # Polish
    ]
    
    for text in examples:
        intent, params = parse_user_intent(text)
        print(f"\nğŸ“ '{text}'")
        print(f"   â†’ Intent: {intent.name}")
        print(f"   â†’ Focus: {params.get('focus', 'person')}")
        print(f"   â†’ Sensitivity: {params.get('sensitivity', 'medium')}")


def demo_llm_selection():
    """Demonstrate LLM selection for different tasks."""
    print("\n" + "="*60)
    print("LLM SELECTION DEMO")
    print("="*60)
    
    tasks = [
        ("detect", False, True, False),   # Quick detection, no vision, prefer speed
        ("summarize", True, True, False), # Summary with vision, prefer speed
        ("describe", True, False, True),  # Full description, prefer quality
        ("compare", False, True, False),  # Compare states, no vision
        ("converse", True, False, True),  # Conversation, prefer quality
    ]
    
    print("\nAvailable LLMs:")
    for name, cap in LLM_REGISTRY.items():
        vision = "ğŸ‘ï¸" if cap.vision else "  "
        print(f"  {vision} {name:20} | {cap.size:6} | {cap.speed:6} | {cap.quality:6} | {cap.cost}")
    
    print("\nBest LLM for each task:")
    for task, vision, speed, quality in tasks:
        best = get_best_llm_for_task(task, require_vision=vision, prefer_speed=speed, prefer_quality=quality)
        print(f"  {task:12} (vision={vision}, speed={speed}, quality={quality}) â†’ {best}")


def demo_pipeline_config():
    """Demonstrate pipeline configuration for different intents."""
    print("\n" + "="*60)
    print("PIPELINE CONFIGURATION DEMO")
    print("="*60)
    
    intents = [
        UserIntent.TRACK_PERSON,
        UserIntent.ALERT_ON_ENTRY,
        UserIntent.SECURITY_WATCH,
        UserIntent.ACTIVITY_LOG,
    ]
    
    for intent in intents:
        pipeline = DetectionPipeline(intent=intent)
        print(f"\nğŸ¯ {intent.name}")
        print(f"   Stages ({len(pipeline._stages)}):")
        for stage in pipeline._stages:
            print(f"     {stage.priority:2}. {stage.method.name:20} | model={stage.model or 'opencv'}")


def demo_from_natural_language():
    """Demonstrate creating pipeline from natural language."""
    print("\n" + "="*60)
    print("NATURAL LANGUAGE PIPELINE DEMO")
    print("="*60)
    
    queries = [
        "notify me when someone enters the room",
        "track the person and tell me what they're doing",
        "security watch with high sensitivity",
        "log all activity in the area",
    ]
    
    for query in queries:
        print(f"\nğŸ“ '{query}'")
        pipeline = DetectionPipeline.from_intent(query)
        print(f"   â†’ Intent: {pipeline.intent.name}")
        print(f"   â†’ Focus: {pipeline.focus}")
        print(f"   â†’ Sensitivity: {pipeline.sensitivity}")
        print(f"   â†’ Stages: {[s.method.name for s in pipeline._stages]}")


def demo_processing_flow():
    """Demonstrate the processing flow (without actual images)."""
    print("\n" + "="*60)
    print("PROCESSING FLOW DEMO")
    print("="*60)
    
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    DETECTION PIPELINE                        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                              â”‚
    â”‚  Frame Input                                                 â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 1: MOTION_OPENCV (~50ms)                      â”‚    â”‚
    â”‚  â”‚   â€¢ Compare with previous frame                     â”‚    â”‚
    â”‚  â”‚   â€¢ motion < 0.5% â†’ SKIP                           â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 2: HOG_PERSON (~100ms)                        â”‚    â”‚
    â”‚  â”‚   â€¢ OpenCV HOG descriptor                           â”‚    â”‚
    â”‚  â”‚   â€¢ No person shape â†’ SKIP (verify every 5th)      â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 3: LLM_QUICK_CHECK (~1-2s) - gemma2:2b       â”‚    â”‚
    â”‚  â”‚   â€¢ "Is there a person?" â†’ YES/NO                  â”‚    â”‚
    â”‚  â”‚   â€¢ NO â†’ SKIP                                       â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 4: LLM_QUICK_SUMMARY (~2s) - gemma2:2b       â”‚    â”‚
    â”‚  â”‚   â€¢ "Person: at desk, using computer"              â”‚    â”‚
    â”‚  â”‚   â€¢ Short-circuit if tracking mode                 â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 5: LLM_CHANGE_CHECK (~1s) - gemma2:2b        â”‚    â”‚
    â”‚  â”‚   â€¢ Compare with previous summary                  â”‚    â”‚
    â”‚  â”‚   â€¢ No change â†’ SKIP                               â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Stage 6: LLM_FULL_DESCRIBE (~5s) - llava:13b       â”‚    â”‚
    â”‚  â”‚   â€¢ Full description (only for security/behavior)  â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚                                                      â”‚
    â”‚       â–¼                                                      â”‚
    â”‚  Result: should_notify, should_speak, should_log            â”‚
    â”‚                                                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


def main():
    parser = argparse.ArgumentParser(description="Smart Detection Pipeline Demo")
    parser.add_argument("--intent", help="Natural language intent to parse")
    parser.add_argument("--all", action="store_true", help="Run all demos")
    args = parser.parse_args()
    
    if args.intent:
        print(f"\nğŸ¯ Parsing intent: '{args.intent}'")
        pipeline = DetectionPipeline.from_intent(args.intent)
        print(f"   Intent: {pipeline.intent.name}")
        print(f"   Focus: {pipeline.focus}")
        print(f"   Sensitivity: {pipeline.sensitivity}")
        print(f"   Stages:")
        for stage in pipeline._stages:
            print(f"     {stage.priority:2}. {stage.method.name}")
    else:
        demo_intent_parsing()
        demo_llm_selection()
        demo_pipeline_config()
        demo_from_natural_language()
        demo_processing_flow()
    
    print("\nâœ… Demo complete!")


if __name__ == "__main__":
    main()
