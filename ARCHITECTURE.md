# Streamware Architecture

## ğŸ“Š Current State Analysis

### Identified Duplications

| Location | Issue | Solution |
|----------|-------|----------|
| `api/generate` calls | 12+ places calling Ollama directly | Use `llm_client.py` everywhere |
| `_call_vision_model` | Duplicated in motion_diff.py, tracking.py | Extract to llm_client |
| TTS code | Was in live_narrator.py + voice.py | âœ… Fixed â†’ `tts.py` |
| env file updates | Was in cli.py + setup.py | âœ… Fixed â†’ `setup_utils.py` |
| "No significant" filtering | In 5+ components | Centralize in response validator |

### Module Dependencies (Current)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        quick_cli.py                          â”‚
â”‚                       (121KB - main CLI)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  core.py  â”‚  â”‚ components/*  â”‚  â”‚  config.py â”‚
â”‚  (flow)   â”‚  â”‚ (12 modules)  â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ llm_client.py â”‚ â”‚   tts.py   â”‚ â”‚ image_optimize.pyâ”‚
â”‚ (centralized) â”‚ â”‚ (unified)  â”‚ â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Refactoring Plan

### Phase 1: Consolidate LLM Calls âœ… (Partial)

**Status:** llm_client.py created, needs adoption

**Tasks:**
1. Update `motion_diff.py` â†’ use `llm_client.vision_query()`
2. Update `tracking.py` â†’ use `llm_client.vision_query()`
3. Update `stream.py` â†’ use `llm_client.vision_query()`
4. Update `smart_monitor.py` â†’ use `llm_client.vision_query()`
5. Update `live_narrator.py` â†’ âœ… Done for `_describe_frame_advanced`
6. Update `media.py` â†’ use `llm_client.vision_query()`

### Phase 2: Response Validation / Filtering

**Goal:** Don't log "nothing happened" responses

**Create `response_filter.py`:**
```python
def is_significant_response(response: str, mode: str = "general") -> bool:
    """Check if LLM response contains meaningful information."""
    noise_patterns = [
        "no significant changes",
        "no movement detected", 
        "no person visible",
        "nothing to report",
        "VISIBLE: NO",
        "PRESENT: NO",
        "CHANGED: NO",
    ]
    response_lower = response.lower()
    return not any(p in response_lower for p in noise_patterns)

def filter_for_logging(response: str) -> Optional[str]:
    """Return response only if significant, else None."""
    if is_significant_response(response):
        return response
    return None
```

### Phase 3: REST API Server

**Create `api_server.py`:**
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="Streamware API")

class AnalyzeRequest(BaseModel):
    image_url: str
    prompt: str
    model: str = "llava:7b"

@app.post("/api/v1/analyze")
async def analyze_image(req: AnalyzeRequest):
    from .llm_client import vision_query
    result = vision_query(req.image_url, req.prompt)
    return {"result": result}

@app.post("/api/v1/live/start")
async def start_live(source: str, mode: str = "track", focus: str = "person"):
    """Start live narrator session"""
    ...

@app.get("/api/v1/live/{session_id}/status")
async def get_live_status(session_id: str):
    ...

@app.post("/api/v1/speak")
async def speak(text: str, engine: str = "auto"):
    from .tts import speak
    success = speak(text)
    return {"success": success}
```

### Phase 4: LLM-Driven Client

**Create `llm_agent.py`:**
```python
class StreamwareAgent:
    """Agent that can be controlled by LLM."""
    
    SYSTEM_PROMPT = '''You are a Streamware automation agent.
    Available commands:
    - analyze_image(path, prompt) - Analyze image with vision LLM
    - start_watch(url, focus) - Start watching camera
    - speak(text) - Speak via TTS
    - query_network() - Scan network for devices
    
    Respond with JSON: {"action": "...", "params": {...}}
    '''
    
    def execute(self, llm_response: dict):
        action = llm_response.get("action")
        params = llm_response.get("params", {})
        
        if action == "analyze_image":
            return vision_query(**params)
        elif action == "start_watch":
            return self._start_watch(**params)
        elif action == "speak":
            return speak(**params)
```

---

## ğŸ“ Target Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ REST API    â”‚  â”‚ CLI (sq)    â”‚  â”‚ Python DSL (Pipeline)  â”‚ â”‚
â”‚  â”‚ (FastAPI)   â”‚  â”‚ (quick_cli) â”‚  â”‚ (dsl.py)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                     â”‚
          â–¼                â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Core Service Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ llm_client.py â”‚  â”‚ response_      â”‚  â”‚ session_manager  â”‚   â”‚
â”‚  â”‚ (all LLM)     â”‚  â”‚ filter.py      â”‚  â”‚ (live sessions)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                     â”‚
          â–¼                â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Component Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ stream   â”‚ â”‚ tracking   â”‚ â”‚ media    â”‚ â”‚ live_narrator   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                     â”‚
          â–¼                â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Infrastructure Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ tts.py        â”‚  â”‚ setup_utils.py â”‚  â”‚ image_optimize   â”‚   â”‚
â”‚  â”‚ (voice)       â”‚  â”‚ (install)      â”‚  â”‚ (preprocessing)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Communication Flow

### Current Flow (sq live --tts)
```
User â†’ quick_cli.py â†’ LiveNarratorComponent
                              â”‚
                              â”œâ”€â†’ ffmpeg (capture)
                              â”œâ”€â†’ FrameAnalyzer (motion)
                              â”œâ”€â†’ requests.post(ollama) â† DUPLICATE
                              â””â”€â†’ tts.speak()
```

### Target Flow
```
User â†’ quick_cli.py â†’ LiveNarratorComponent
                              â”‚
                              â”œâ”€â†’ ffmpeg (capture)
                              â”œâ”€â†’ FrameAnalyzer (motion)
                              â”œâ”€â†’ llm_client.analyze_image()
                              â”‚         â”‚
                              â”‚         â””â”€â†’ response_filter.is_significant()
                              â”‚                    â”‚
                              â”‚                    â”œâ”€â†’ True: log + tts
                              â”‚                    â””â”€â†’ False: skip
                              â””â”€â†’ tts.speak() (only if significant)
```

---

## âœ… Completed

1. âœ… **`response_filter.py`** - filter noise from LLM responses
2. âœ… **Guarder model** - small LLM (qwen2.5:3b) validates responses before logging
3. âœ… **Significance check** in live_narrator - skip "no change" responses
4. âœ… **`--guarder` flag** - enable LLM validation via CLI
5. âœ… **`--lite` flag** - reduce memory usage

## ğŸ”„ Next Steps

1. **Migrate all Ollama calls** to `llm_client.py` (partial)
2. **Create REST API** with FastAPI (optional)
3. **Create LLM Agent** for natural language control

---

## ğŸ›¡ï¸ Guarder Model

Small LLM that validates vision model responses before logging:

```bash
# Enable via CLI
sq live narrator --url "rtsp://..." --guarder

# Or via .env
SQ_USE_GUARDER=true
SQ_GUARDER_MODEL=qwen2.5:3b
```

**Recommended models (3B, fast):**
| Model | Size | Speed | Quality |
|-------|------|-------|---------|
| `qwen2.5:3b` | 2GB | Fast | Best |
| `phi3:mini` | 2.3GB | Fast | Good |
| `gemma2:2b` | 1.6GB | Fastest | OK |
| `llama3.2:3b` | 2GB | Fast | Good |

**Flow:**
```
Vision LLM (llava:7b) â†’ Response â†’ Guarder (qwen2.5:3b) â†’ YES/NO â†’ Log/Skip
```

**Auto-install at startup:**
```
sq live narrator --url "rtsp://..."

âš ï¸  Model qwen2.5:3b not found. Install with: ollama pull qwen2.5:3b

   Guarder model 'qwen2.5:3b' is needed for smart response filtering.
   Recommended models (small, fast):
   1. qwen2.5:3b  - Best quality (2GB)
   2. gemma2:2b   - Fastest (1.6GB)
   3. phi3:mini   - Good balance (2.3GB)
   4. Skip        - Use regex filtering only

   Install model? [1-4, default=1]: 1

   Pulling qwen2.5:3b... (this may take a few minutes)
   âœ… qwen2.5:3b installed successfully
```

---

## ğŸ“ Module Structure

```
streamware/
â”œâ”€â”€ cli.py              # Main CLI (streamware command)
â”œâ”€â”€ quick_cli.py        # sq command (121KB)
â”œâ”€â”€ core.py             # Flow engine
â”œâ”€â”€ config.py           # Configuration management
â”œâ”€â”€ dsl.py              # Python DSL (Pipeline)
â”‚
â”œâ”€â”€ llm_client.py       # Centralized LLM client âœ…
â”œâ”€â”€ tts.py              # Unified TTS module âœ…
â”œâ”€â”€ response_filter.py  # Smart response filtering âœ…
â”œâ”€â”€ image_optimize.py   # Image preprocessing
â”œâ”€â”€ setup_utils.py      # Cross-platform setup âœ…
â”‚
â”œâ”€â”€ prompts/            # External prompt templates
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stream_diff.txt
â”‚   â”œâ”€â”€ live_narrator_*.txt
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ components/         # Core components
    â”œâ”€â”€ live_narrator.py
    â”œâ”€â”€ stream.py
    â”œâ”€â”€ tracking.py
    â”œâ”€â”€ motion_diff.py
    â”œâ”€â”€ smart_monitor.py
    â””â”€â”€ ...
```
